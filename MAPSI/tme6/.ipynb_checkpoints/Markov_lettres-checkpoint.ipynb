{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME sur la classification de lettres manuscrites\n",
    "## Format des données\n",
    "Nous travaillerons sur des lettres manuscrites.\n",
    "Les données sont fournies au format pickle (le standard de sérialisation python, particulièrement convivial). Pour les charger : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named _multiarray_umath",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mImportError\u001b[0m: No module named _multiarray_umath"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-02313c2afce2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ressources/lettres.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pylab_helpers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/matplotlib/colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontour\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridspec\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgridspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/matplotlib/contour.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_contour\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_contour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('ressources/lettres.pkl', 'rb') as f:\n",
    "    data = pkl.load(f, encoding='latin1') \n",
    "X = np.array(data.get('letters')) # récupération des données sur les lettres\n",
    "Y = np.array(data.get('labels')) # récupération des étiquettes associées "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont dans un format original: une lettre est en fait une série d'angles (exprimés en degrés). Un exemple: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de l'acquisition, un stylo intelligent a pris des mesures régulièrement dans le temps: chaque période correspond à un segment de droite et le stylo a calculé l'angle entre deux segments consécutifs... C'est l'information qui vous est fournie.\n",
    "\n",
    "Pour afficher une lettre, il faut reconstruire la trajectoire enregistrée... C'est ce que fait la méthode ci-dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage d'une lettre\n",
    "def tracerLettre(let):\n",
    "    a = -let*np.pi/180; # conversion en rad\n",
    "    coord = np.array([[0, 0]]); # point initial\n",
    "    for i in range(len(a)):\n",
    "        x = np.array([[1, 0]]);\n",
    "        rot = np.array([[np.cos(a[i]), -np.sin(a[i])],[ np.sin(a[i]),np.cos(a[i])]])\n",
    "        xr = x.dot(rot) # application de la rotation\n",
    "        coord = np.vstack((coord,xr+coord[-1,:]))\n",
    "    plt.figure()\n",
    "    plt.plot(coord[:,0],coord[:,1])\n",
    "    plt.savefig(\"exlettre.png\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracerLettre(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Apprentissage d'un modèle CM (max de vraisemblance)\n",
    "### 1. Discrétisation\n",
    "\n",
    "**1 état = 1 angle**\n",
    "\n",
    "Il est nécessaire de regrouper les angles en un nombre fini d'états (par exemple 20)\n",
    "- définir un `intervalle = 360 / n_etats`\n",
    "- discrétiser tous les signaux à l'aide de la formule `np.floor(x / intervalle)`\n",
    "\n",
    "Donner le code de la méthode `discretise(x, d)` qui prend la base des signaux et retourne une base de signaux discrétisés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretise(x, d):\n",
    "    intervalle = 360 / d\n",
    "    return np.floor(x / intervalle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VALIDATION :** code du premier signal avec une discrétisation sur 3 états:\n",
    "```python\n",
    "array([ 0.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.,  1.,  1.,  1., 1., 1., 2., 2.,  2.,\n",
    "       2.,  0.,  0.,  0.,  0.,  0.])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Regrouper les indices des signaux par classe (pour faciliter l'apprentissage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupByLabel(y):\n",
    "    index = []\n",
    "    for i in np.unique(y): # pour toutes les classes\n",
    "        ind, = np.where(y == i)\n",
    "        index.append(ind)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette méthode produit simplement une structure type:\n",
    "```python\n",
    "[array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
    " array([11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]),\n",
    " array([22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]),\n",
    " array([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]),\n",
    " array([44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]),\n",
    " array([55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65]),\n",
    " ...\n",
    "```\n",
    "Chaque ligne regroupe les indices de signaux correspondant à une classe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Apprendre les modèles CM\n",
    "\n",
    "Soit {$X_C$} la base de signaux discrétisés correspondant à une classe {$C$} et {$d$} le nombre d'états. Donner le code de la fonction `learnMarkovModel(Xc, d)` qui retourne un tuple contenant Pi et A.\n",
    "\n",
    "Rappel:\n",
    "- Initialisation de \n",
    "```python\n",
    " A = np.zeros((d, d))\n",
    " Pi = np.zeros(d)```\n",
    "- Parcours de tous les signaux et incréments de A et Pi\n",
    "- Normalisation (un peu réfléchie pour éviter les divisions par 0)\n",
    "```python\n",
    "A = A / np.maximum(A.sum(1).reshape(d, 1), 1) # normalisation\n",
    "Pi = Pi / Pi.sum()```\n",
    "\n",
    "**Note** : la solution proposée pour gérer le cas des lignes entièrement à 0 est naïve et n'est pas totalement satisfaisante. Comprendre pourquoi. On proposera une solution améliorée plus loin dans le TME. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnMarkovModel(Xc, d):\n",
    "    \n",
    "    # votre code\n",
    "    \n",
    "    return Pi, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation :** premier modèle avec une discrétisation sur 3 états :\n",
    "```python\n",
    "(array([ 0.36363636,  0.        ,  0.63636364]),\n",
    " array([[ 0.84444444,  0.06666667,  0.08888889],\n",
    "       [ 0.        ,  0.83333333,  0.16666667],\n",
    "       [ 0.11382114,  0.06504065,  0.82113821]]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Stocker les modèles dans une liste\n",
    "\n",
    "Pour un usage ultérieur plus facile, on utilise le code suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 20                   # paramètre de discrétisation\n",
    "Xd = discretise(X, d)    # application de la discrétisation\n",
    "index = groupByLabel(Y)  # groupement des signaux par classe\n",
    "models = []\n",
    "for cl in range(len(np.unique(Y))): # parcours de toutes les classes et optimisation des modèles\n",
    "    models.append(learnMarkovModel(Xd[index[cl]], d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test (affectation dans les classes sur critère MV)\n",
    "### 1. (log)Probabilité d'une séquence dans un modèle\n",
    "\n",
    "Donner le code de la méthode `probaSequence(s,Pi,A)` qui retourne la log-probabilité d'une séquence `s` dans le modèle {$\\lambda=\\{Pi,A\\}$} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probaSequence(s, Pi, A):\n",
    "    res = np.log(Pi[s[0]])\n",
    "    for i in range(1, len(s)):\n",
    "        res += np.log(A[s[i-1],s[i]])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VALIDATION :** probabilité du premier signal dans les 26 modèles avec une discrétisation sur 3 états :\n",
    "```python\n",
    "array([-13.491086  ,         -inf,         -inf,         -inf,\n",
    "               -inf,         -inf,         -inf,         -inf,\n",
    "               -inf,         -inf,         -inf,         -inf,\n",
    "               -inf,         -inf,         -inf,         -inf,\n",
    "               -inf,         -inf,         -inf,         -inf,\n",
    "               -inf,         -inf,         -inf,         -inf,\n",
    "               -inf, -12.48285678])\n",
    "```\n",
    "\n",
    "- Ce signal est-il bien classé ?\n",
    "- D'où viennent tous les `-inf` ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Application de la méthode précédente pour tous les signaux et tous les modèles de lettres\n",
    "\n",
    "L'application se fait en une ligne de code si vous avez respecté les spécifications précédentes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = np.array([[probaSequence(Xd[i], models[cl][0], models[cl][1]) for i in range(len(Xd))]\n",
    "                  for cl in range(len(np.unique(Y)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation des performances\n",
    "\n",
    "Pour l'évaluation, nous proposons l'approche suivante: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul d'une version numérique des Y :\n",
    "Ynum = np.zeros(Y.shape)\n",
    "for num, char in enumerate(np.unique(Y)):\n",
    "    Ynum[Y == char] = num\n",
    "    \n",
    "# Calcul de la classe la plus probable :\n",
    "pred = proba.argmax(0) # max colonne par colonne\n",
    "\n",
    "# Calcul d'un pourcentage de bonne classification :\n",
    "np.where(pred != Ynum, 0.,1.).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INDICE DE PERFORMANCE :** 91% de bonne classification avec 20 états, 69% avec 3 états"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biais d'évaluation, notion de sur-apprentissage\n",
    "\n",
    "Dans le protocole précédent, nous avons triché:\n",
    "- les données servent d'abord à apprendre les modèles...\n",
    "- puis nous nous servons des mêmes données pour tester les modèles ! Les performances sont forcément bonnes ! \n",
    "\n",
    "Afin de palier le problème, nous allons diviser en deux la base de données: une partie servira à l'apprentissage des modèles, l'autre à leur évaluation. Pour effectuer la division, nous fournissons le code suivant: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separation app/test, pc=ratio de points en apprentissage\n",
    "def separeTrainTest(y, pc):\n",
    "    indTrain = []\n",
    "    indTest = []\n",
    "    for i in np.unique(y): # pour toutes les classes\n",
    "        ind, = np.where(y == i)\n",
    "        n = len(ind)\n",
    "        indTrain.append(ind[np.random.permutation(n)][:int(np.floor(pc * n))])\n",
    "        indTest.append(np.setdiff1d(ind, indTrain[-1]))\n",
    "    return indTrain, indTest\n",
    "\n",
    "# exemple d'utilisation\n",
    "itrain, itest = separeTrainTest(Y, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dans `itrain`, nous obtenons les indices des signaux qui doivent servir en apprentissage pour chaque classe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :** pour faciliter l'évaluation des modèles, vous aurez besoin de re-fusionner tous les indices d'apprentissage et de test. Cela se fait avec les lignes de code suivantes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia = []\n",
    "for i in itrain:\n",
    "    ia += i.tolist()    \n",
    "it = []\n",
    "for i in itest:\n",
    "    it += i.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note 2 :** Du fait de la permutation aléatoire, les résultats vont bouger (un peu) à chaque execution du programme. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions importantes\n",
    "- Ré-utiliser les fonctions précédemment définies pour apprendre des modèles et les évaluer sans biais.\n",
    "- Calculer et analyser les résultats obtenus en apprentissage et en test\n",
    "- Etudier l'évolution des performances en fonction de la discrétisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lutter contre le sur-apprentissage\n",
    "Cette base de données met en lumière le phénomène de sur-apprentissage : il y a peu de données et dès que le nombre d'états augmente, il y a trop peu d'exemple pour estimer correctement les matrices {$A, \\pi$}. De nombreuses cases sont donc à 0, voire des lignes entières (d'où la sécurisation du code pour la normalisation des matrices stochastiques).\n",
    "\n",
    "Ces 0 sont particulièrement discriminants: considérant la classe {$c$}, ils permettent d'éliminer de cette classe tout signal présentant cette caractéristique. Cette règle est trop forte compte tenu de la taille de la base d'apprentissage. Nous proposons une astuce pour palier cette faiblesse : lors du comptage, initialiser les matrices {$A, \\pi$} avec ones au lieu de zeros . On fait semblant d'avoir observer une transition de chaque type avant même le début du comptage.\n",
    "\n",
    "Comparer les performances en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie optionnelle\n",
    "## Evaluation qualitative\n",
    "\n",
    "Nous nous demandons maintenant où se trouvent les erreurs que nous avons commises...\n",
    "\n",
    "Calcul de la matrice de confusion: pour chaque échantillon de test, nous avons une prédiction (issue du modèle) et une vérité terrain (la vraie étiquette). En posant Nc le nombre de classes, la matrice de confusion est une matrice (Nc x Nc) où nous comptons le nombre d'échantillon de test dans chaque catégorie :\n",
    "\n",
    "- Initialisation à 0 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = np.zeros((26,26))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pour chaque échantillon, incrément de la case (prediction, vérité)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tracé de la matrice : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(conf, interpolation = 'nearest')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(26), np.unique(Y))\n",
    "plt.yticks(np.arange(26), np.unique(Y))\n",
    "plt.xlabel(u'Vérité terrain')\n",
    "plt.ylabel(u'Prédiction')\n",
    "plt.savefig(\"mat_conf_lettres.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle génératif\n",
    "\n",
    "Utiliser les modèles appris pour générer de nouvelles lettres manuscrites.\n",
    "\n",
    "### Tirage selon une loi de probabilité discrète\n",
    "\n",
    "- faire la somme cumulée de la loi {$sc$}\n",
    "- tirer un nombre aléatoire {$t$} entre 0 et 1\n",
    "- trouver la première valeur de {$sc$} qui est supérieure à {$t$}\n",
    "- retourner cet état \n",
    "\n",
    "**Note :** comme vu en cours, tout repose sur la somme cumulée (notée ici `sc$`, calculable en appelant `np.cumsum`. Sur un exemple: la loi `V = [0.2, 0.4, 0.3, 0.1]` a pour somme cumulée `V.cumsum() == [0.2,  0.6,  0.9,  1.0]`\n",
    "\n",
    "### Génération d'une séquence de longueur N\n",
    "\n",
    "- tirer un état {$s_0$} selon Pi\n",
    "- tant que la longueur n'est pas atteinte :\n",
    "  - tirer un état {$s_{t+1}$} selon {$A[s_{t}]$} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage du résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newa = generate(models[0][0], models[0][1], 20)       # generation d'une séquence d'états\n",
    "intervalle = 360. / d                                 # pour passer des états => valeur d'angles\n",
    "newa_continu = np.array([i * intervalle for i in newa]) # conv int => double\n",
    "tracerLettre(newa_continu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
